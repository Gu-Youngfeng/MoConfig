#!/usr/bin/python3
# coding=utf-8

"""
@desription: This file uses the sampling set generated by MoConfig and predict the test set.
----------------------------
@author: yongfeng
@update: 2019.7.31
"""

import pandas as pd
import numpy as np
import os
from pandas import DataFrame
import random
from sklearn.utils import shuffle
from sklearn.tree import DecisionTreeRegressor
import warnings
import re


class config:
    def __init__(self, id, decisions, objective, rank):
        self.id = id
        self.decision = decisions
        self.objective = objective
        self.rank = rank


class predicted_config:
    def __init__(self,decisions,objective,truly_rank,predicted,pre_rank):
        self.decision = decisions
        self.objective = objective
        self.truly_rank = truly_rank
        self.predicted = predicted
        self.pre_rank = pre_rank


def predict_on_test(train, test):
    train_independent = [t.decision for t in train]
    train_dependent = [t.objective for t in train]

    sorted_test = sorted(test, key=lambda x: x.objective) # sorted by actual performance
    # for r, st in enumerate(sorted_test): st.rank = r
    test_independent = [t.decision for t in sorted_test]
    test_dependent = [t.objective for t in sorted_test]

    model = DecisionTreeRegressor()
    model.fit(train_independent, train_dependent)
    predicted = model.predict(test_independent)
    predicted_id = [[i, p] for i, p in enumerate(predicted)]

    # random.shuffle(predicted_id)  # patch: patch for the old version of the rank-based approach
    # predicted_sorted = sorted(predicted_id, key=lambda x: x[-1])
    # predicted_rank_sorted = [[p[0], p[-1], i] for i,p in enumerate(predicted_sorted)]
    # select_few = predicted_rank_sorted[:10]   # the min predicted rank
    
    test_content = list()
    for c in range(len(sorted_test)):
        test_config = predicted_config(test_independent[c], test_dependent[c], c+1, predicted[c], c+1)
        test_content.append(test_config)

    random.shuffle(test_content)  # patch: patch for the old version of the rank-based approach
    predicted_sorts = sorted(test_content,key = lambda x : x.predicted)
    for r, st in enumerate(predicted_sorts): st.pre_rank = r+1
    # select_few_modify = [t.truly_rank - 1 for t in predicted_sorts]
    
    return predicted_sorts


def moconfig(train_path, test_path):

	resultfolder = "experiments/moconfig/"
	reg_name = os.path.basename(train_path)  # e.g., rs-6d-c3-obj1_0.csv_NUMSAMPLE_DENSITY_DBEA_0_429.000000.csv
	print(reg_name)
	pattern = "(.*)_0.csv_(\w*)_(\w*)_(\w*)_(\d*)_(.*).csv"
	matchObj = re.match(pattern, reg_name)
	proj_name = ""
	obj1 = ""
	obj2 = ""
	samples = ""
	if matchObj:
		proj_name = matchObj.group(1)
		obj1 = matchObj.group(2)
		obj2 = matchObj.group(3)
		method = matchObj.group(4)
		samples = matchObj.group(6)
		# print(proj_name,": ",obj1," &",obj2,"-", method, ":", samples)

	output_dir = resultfolder + proj_name + '/' + method + '/' + obj1 + '_' + obj2
	if not os.path.exists(output_dir):	
		os.makedirs(output_dir)

	train_content = pd.read_csv(train_path)
	train_indepcolumns = train_content.columns[:-1]
	train_depcolumns = train_content.columns[-1]
	sorted_pdcontent = train_content.sort_values(train_depcolumns)  # sorted by performance

	train_set = []
	for c in range(len(train_content)):
		single_config = config(c, sorted_pdcontent.iloc[c][train_indepcolumns].tolist(), sorted_pdcontent.iloc[c][train_depcolumns], c)
		train_set.append(single_config)
	random.shuffle(train_set)

	test_content = pd.read_csv(test_path)
	test_indepcolumns = test_content.columns[:-1]
	test_depcolumns = test_content.columns[-1]
	sorted_pdcontent = test_content.sort_values(test_depcolumns)  # sorted by performance

	test_set = []
	for c in range(len(test_content)):
		single_config = config(c, sorted_pdcontent.iloc[c][test_indepcolumns].tolist(), sorted_pdcontent.iloc[c][test_depcolumns], c)
		test_set.append(single_config)
	random.shuffle(test_set)

	predicted_sorts = predict_on_test(train_set, test_set)

	test_data = DataFrame()
	test_data['Feature'] = [t.decision for t in predicted_sorts]
	test_data['Actual_Performance'] = [t.objective for t in predicted_sorts]
	test_data['Actual_Rank'] = [t.truly_rank for t in predicted_sorts]
	test_data['MoConfig_Performance'] = [t.predicted for t in predicted_sorts]
	test_data['MoConfig_Rank'] = [t.pre_rank for t in predicted_sorts]

	# print(output_dir + "/moconfig")
	test_data.to_csv(output_dir + '/moconfig_' + samples + '.csv', index=False)


def initialize_moconfig():
	print(">> predict on test set using the moConfig sampling ...")

	testfolder = "parse_data/split_data/"
	monfolder = "../MoConfigSampling/testbed/output/"

	projs = [f for f in os.listdir(monfolder)]  # data in output directory
	print(projs)

	for proj in projs:
		train_paths = os.listdir(monfolder + proj)  # selected set by moconfig sampling
		test_path = testfolder + proj + "/split0/test_set.csv"

		for path in train_paths:
			train_path = monfolder + proj + "/" + path
			moconfig(train_path, test_path)


if __name__ == "__main__":
	# start of the MoConfig
	initialize_moconfig()